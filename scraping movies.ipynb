{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      " * Restarting with stat\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001B[1;31mSystemExit\u001B[0m\u001B[1;31m:\u001B[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prince\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3406: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Dec 16 00:55:48 2018\n",
    "\n",
    "@author: Kunal N Pandey\n",
    "\"\"\"\n",
    "\n",
    "from flask import Flask, render_template, request\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from requests import get\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "\n",
    "def actual_name(response):\n",
    "    movie_page = BeautifulSoup(response.text, 'lxml')\n",
    "    title_bar = movie_page.find('div', class_='title_wrapper')\n",
    "    name = str(title_bar.find('h1').text)\n",
    "    return name[0:-8]\n",
    "\n",
    "\n",
    "def IMDB_rating(response):\n",
    "    rating_bar = BeautifulSoup(response.text, 'lxml')\n",
    "    page_text = rating_bar.find('div', class_='ratingValue')\n",
    "    rating = str(page_text.find('span', itemprop='ratingValue').text)\n",
    "    return rating\n",
    "\n",
    "\n",
    "def rotten_tomato(response):\n",
    "    page = BeautifulSoup(response.text, 'lxml')\n",
    "    critics_rating_bar = page.find('div', id=\"scoreStats\").text\n",
    "    critics_rating = critics_rating_bar[25::]\n",
    "    critics_rating = critics_rating.strip()\n",
    "    e1_index = critics_rating.index('/')\n",
    "    aud_rating_bar = page.find('div', class_='audience-info hidden-xs superPageFontColor').text\n",
    "    aud_rating = aud_rating_bar[25::]\n",
    "    aud_rating = aud_rating.strip()\n",
    "    e2_index = aud_rating.index('/')\n",
    "    return critics_rating[0:e1_index], aud_rating[0:e2_index]\n",
    "\n",
    "\n",
    "def no_of_votes(response):\n",
    "    movie_page = BeautifulSoup(response.text, 'lxml')\n",
    "    votes = str(movie_page.find('span', itemprop='ratingCount').text)\n",
    "    return votes\n",
    "\n",
    "\n",
    "def release_year(response):\n",
    "    movie_page = BeautifulSoup(response.text, 'lxml')\n",
    "    try:\n",
    "        year = movie_page.find('span', id='titleYear').text\n",
    "        year = str(year[1:len(year) - 1])\n",
    "        return year\n",
    "    except AttributeError:\n",
    "        return \"Not Available\"\n",
    "\n",
    "\n",
    "def imdb_cast(response):\n",
    "    l = []\n",
    "    try:\n",
    "        txt = response.text\n",
    "        start = [m.start() for m in re.finditer('Stars', txt)]\n",
    "        txt = txt[start[0]::]\n",
    "        end = [m.start() for m in re.finditer('<span', txt)]\n",
    "        txt = txt[0:end[0]]\n",
    "        end = [m.start() for m in re.finditer('<a', txt)]\n",
    "        txt = txt[end[0]::]\n",
    "        while (len(txt) > 0):\n",
    "            try:\n",
    "                end = [m.start() for m in re.finditer('>', txt)]\n",
    "                txt = txt[end[0] + 1::]\n",
    "                end = [m.start() for m in re.finditer('<', txt)]\n",
    "                l.append(txt[0:end[0]])\n",
    "                end = [m.start() for m in re.finditer('<a', txt)]\n",
    "                txt = txt[end[0]::]\n",
    "            except IndexError:\n",
    "                break\n",
    "    except IndexError:\n",
    "        return l\n",
    "    return l\n",
    "\n",
    "\n",
    "def wiki_cast(response):\n",
    "    l = []\n",
    "    try:\n",
    "        txt = response.text\n",
    "        start = [m.start() for m in re.finditer('Starring', txt)]\n",
    "        txt = txt[start[0]::]\n",
    "        end = [m.start() for m in re.finditer('/td>', txt)]\n",
    "        txt = txt[0:end[0]]\n",
    "        end = [m.start() for m in re.finditer('<a', txt)]\n",
    "        txt = txt[end[0]::]\n",
    "        while (len(txt) > 0):\n",
    "            try:\n",
    "                end = [m.start() for m in re.finditer('\">', txt)]\n",
    "                txt = txt[end[0] + 2::]\n",
    "                end = [m.start() for m in re.finditer('<', txt)]\n",
    "                l.append(txt[0:end[0]])\n",
    "                end = [m.start() for m in re.finditer('<a', txt)]\n",
    "                txt = txt[end[0]::]\n",
    "            except IndexError:\n",
    "                break\n",
    "        return l\n",
    "    except IndexError:\n",
    "        return l\n",
    "\n",
    "\n",
    "def box_office_wiki(response):\n",
    "    s = \"\"\n",
    "    txt = response.text\n",
    "    start = [m.start() for m in re.finditer('Box office', txt)]\n",
    "    txt = txt[start[0]::]\n",
    "    start = [m.start() for m in re.finditer('Box office', txt)]\n",
    "    end = [m.start() for m in re.finditer('/td>', txt)]\n",
    "    txt = txt[0:end[0]]\n",
    "    txt2 = \"\"\n",
    "    try:\n",
    "        end = [m.start() for m in re.finditer('wrap\">', txt)]\n",
    "        txt = txt[end[0] + 6::]\n",
    "        end = [m.start() for m in re.finditer('<', txt)]\n",
    "        s = s + txt[0:end[0]]\n",
    "        end = [m.start() for m in re.finditer('/span>', txt)]\n",
    "        txt = txt[end[0] + 6::]\n",
    "        txt2 = txt\n",
    "        end = [m.start() for m in re.finditer('<', txt)]\n",
    "        txt = txt[0:end[0]]\n",
    "        s = s + \" \" + txt\n",
    "    except IndexError:\n",
    "        start = [m.start() for m in re.finditer('<td>', txt)]\n",
    "        txt = txt[start[0] + 4::]\n",
    "        end = [m.start() for m in re.finditer('<', txt)]\n",
    "        s = s + txt[0:end[0]]\n",
    "    s.strip()\n",
    "    if (len(s) <= 8):\n",
    "        try:\n",
    "            end = [m.start() for m in re.finditer('/span>', txt2)]\n",
    "            txt2 = txt2[end[0] + 6::]\n",
    "            end = [m.start() for m in re.finditer('<', txt2)]\n",
    "            txt2 = txt2[0:end[0]]\n",
    "        except IndexError:\n",
    "            txt2 = txt2.strip()\n",
    "\n",
    "        s = s + \" \" + txt2\n",
    "\n",
    "    return s\n",
    "\n",
    "\n",
    "def box_office_imdb(response):\n",
    "    try:\n",
    "        txt = response.text\n",
    "        start = [m.start() for m in re.finditer('Worldwide Gross:', txt)]\n",
    "        txt = txt[start[0]::]\n",
    "        end = [m.start() for m in re.finditer('/div>', txt)]\n",
    "        txt = txt[22:end[0]]\n",
    "        end = [m.start() for m in re.finditer('<', txt)]\n",
    "        txt = txt[0:end[0]]\n",
    "        txt.strip()\n",
    "        return txt\n",
    "    except IndexError:\n",
    "        s = \"\"\n",
    "        return s\n",
    "\n",
    "\n",
    "def get_other_details(response):\n",
    "    li = []\n",
    "    page = BeautifulSoup(response.text, 'lxml')\n",
    "    details = (page.find('div', class_=\"subtext\")).text\n",
    "    for i in range(0, 3):\n",
    "        index = details.find('|')\n",
    "        s = details[0:index].strip()\n",
    "        s = s.replace(\"\\n\", \"\")\n",
    "        if (len(li) == 0):\n",
    "            if (s[0] == '1'):\n",
    "                li.append('UA')\n",
    "            elif (s[0] == '2'):\n",
    "                li.append('UA')\n",
    "        li.append(s)\n",
    "        details = details[index + 1::]\n",
    "    return li\n",
    "\n",
    "\n",
    "def get_poster_array(response):\n",
    "    txt = response.text\n",
    "    start = [m.start() for m in re.finditer('class=\"poster\"', txt)]\n",
    "    txt = txt[start[0]::]\n",
    "    end = [m.start() for m in re.finditer('</a>', txt)]\n",
    "    txt = txt[0:end[0]]\n",
    "    start = [m.start() for m in re.finditer('src=\"', txt)]\n",
    "    txt = txt[start[0] + 5::]\n",
    "    end = [m.start() for m in re.finditer('\" />', txt)]\n",
    "    txt = txt[0:end[0]]\n",
    "    resource = urllib.request.urlopen(txt)\n",
    "    output = open(\"static/file01.jpg\", \"wb\")\n",
    "    output.write(resource.read())\n",
    "    output.close()\n",
    "    '''\n",
    "    img=plt.imread('/static/file01.jpg',1)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Poster of \" +title)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    return img\n",
    "    '''\n",
    "\n",
    "\n",
    "def show_poster(img, title):\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Poster of \" + title)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_link(movie_name, key, z):\n",
    "    url = \"https://in.search.yahoo.com/search?p=\" + movie_name + \"+\" + key\n",
    "    response = get(url)\n",
    "    html_soup = BeautifulSoup(response.text, 'lxml')\n",
    "    page_link = \"\"\n",
    "    for link in html_soup.find_all('a', href=True):\n",
    "        if z in link['href']:\n",
    "            page_link = link['href']\n",
    "            break\n",
    "    return page_link\n",
    "\n",
    "\n",
    "def bar_plot(name, rating, title, max_limit):\n",
    "    x = np.arange(len(name))\n",
    "    plt.title(title)\n",
    "    plt.xticks(x, name)\n",
    "    plt.ylabel(\"Rating\")\n",
    "    plt.ylim(0, max_limit, 1)\n",
    "    barlist = plt.bar(x, rating)\n",
    "    plt.grid(1, 'major', 'y')\n",
    "    for i in range(0, len(barlist)):\n",
    "        if (rating[i] / max_limit < 0.65):\n",
    "            barlist[i].set_color('r')\n",
    "        elif (rating[i] / max_limit >= 0.8):\n",
    "            barlist[i].set_color('g')\n",
    "        else:\n",
    "            barlist[i].set_color('y')\n",
    "    for a, b in zip(x, rating):\n",
    "        plt.text(a, b, str(b)[0:3], fontsize=10)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def movieDetail(s):\n",
    "    msg = \"\"\n",
    "    imdb_rating = []\n",
    "    rot_tom_critics = []\n",
    "    rot_tom_audience = []\n",
    "    average_rating = []\n",
    "    name = []\n",
    "    poster = []\n",
    "    li = list(map(str, s.split(',')))\n",
    "    # li=['The GodFather','Boss(Hindi)' ,'P K']\n",
    "    f = 0\n",
    "    for movie in li:\n",
    "\n",
    "        imdb_page_link = get_link(movie, \"movie+imdb\", \"www.imdb.com\")\n",
    "        wiki_page_link = get_link(movie, \"movie+wikipedia\", 'https://en.wikipedia.org')\n",
    "        rotten_tomato_page_link = get_link(movie, \"movie+rotten+tomato\", 'https://www.rottentomatoes.com')\n",
    "        response_1 = get(imdb_page_link)\n",
    "\n",
    "        response_2 = get(wiki_page_link)\n",
    "\n",
    "        response_3 = get(rotten_tomato_page_link)\n",
    "\n",
    "        act_name = actual_name(response_1)\n",
    "        poster.append(get_poster_array(response_1))\n",
    "\n",
    "        name.append(act_name)\n",
    "        msg = msg + \"\\nMovie Name : \" + act_name\n",
    "\n",
    "        year = release_year(response_1)\n",
    "        msg = msg + \"\\nRelease Year : \" + year\n",
    "\n",
    "        rating = IMDB_rating(response_1)\n",
    "        votes = no_of_votes(response_1)\n",
    "        msg = msg + \"\\nIMDB Rating : \" + str(rating) + \"/10 (based on \" + str(votes) + \" votes)\"\n",
    "        imdb_rating.append(float(rating))\n",
    "\n",
    "        try:\n",
    "            critics, audience = rotten_tomato(response_3)\n",
    "            rot_tom_critics.append(float(critics))\n",
    "            rot_tom_audience.append(float(audience))\n",
    "            average_rating.append((float(rating) + float(critics) + float(audience) * 2) / 3)\n",
    "            msg = msg + \"\\nRotten Tomato Critics rating : \" + critics + \"/10\"\n",
    "            msg = msg + \"\\nRotten Tomato Audience rating : \" + audience + \"/5\"\n",
    "        except AttributeError:\n",
    "            f = 1\n",
    "\n",
    "        lis = get_other_details(response_1)\n",
    "        if (len(lis) >= 3):\n",
    "            msg = msg + \"\\nGenre : \" + lis[2]\n",
    "            msg = msg + \"\\nCertificate : \" + lis[0]\n",
    "            msg = msg + \"\\nDuration : \" + lis[1]\n",
    "\n",
    "        collection = box_office_imdb(response_1)\n",
    "        if (len(collection) == 0):\n",
    "            try:\n",
    "                collection = box_office_wiki(response_2)\n",
    "                if (len(collection) > 8):\n",
    "                    msg = msg + \"\\nBox Office Collection : \" + collection\n",
    "                else:\n",
    "                    msg = msg + \"\\nBox Office Collection : Not Available\"\n",
    "            except IndexError:\n",
    "                msg = msg + \"\\nBox Office Collection : Not Available\"\n",
    "        else:\n",
    "            msg = msg + \"\\nBox Office Collection : \" + collection\n",
    "\n",
    "        starring_1 = imdb_cast(response_1)\n",
    "        starring_2 = wiki_cast(response_2)\n",
    "        starring = starring_1 + list(set(starring_2) - set(starring_1))\n",
    "        msg = msg + \"\\nStarring : \"\n",
    "        for i in range(len(starring)):\n",
    "            msg = msg + \"\\n\" + str(i + 1) + '.' + starring[i]\n",
    "\n",
    "        msg = msg + \"\\n\\n\\n\"\n",
    "    '''\n",
    "    if(len(li)>=2):\n",
    "        if f==0:\n",
    "            bar_plot(name,imdb_rating,\"IMDB Rating\",10)\n",
    "            bar_plot(name,rot_tom_critics,\"Critics Rating(Rotten Tomato)\",10)\n",
    "            bar_plot(name,rot_tom_audience,\"Audience Rating(Rotten Tomato)\",5)\n",
    "            bar_plot(name,average_rating,\"Average Rating(Based on IMDB and Rotten Tomato)\",10)\n",
    "        else:\n",
    "            bar_plot(name,imdb_rating,\"IMDB Rating\",10)\n",
    "\n",
    "        s=input(\"Do you want the posters of your Queried Movies?\\n\")\n",
    "        s=s.lower()\n",
    "        if(s==\"yes\"):\n",
    "            for i in range(len(poster)):\n",
    "                show_poster(poster[i],name[i])\n",
    "    else:\n",
    "        show_poster(poster[0],name[0])\n",
    "\n",
    "    print(\"Hint-If You are not getting the desired result try searching \\n\\twith including the original language of the movie\")\n",
    "    '''\n",
    "    return msg\n",
    "\n",
    "\n",
    "def seriesDetail(s):\n",
    "    myresult = list(map(str, s.split(',')))\n",
    "    message = \"\"\n",
    "    for x in myresult:\n",
    "        s = \"\"\n",
    "        for i in range(len(x)):\n",
    "            if (x[i] == \" \"):\n",
    "                s = s + \"+\"\n",
    "            else:\n",
    "                s = s + \"\" + x[i]\n",
    "        s = s + \"+Tv+Series+imdb\"\n",
    "        url1 = \"https://in.search.yahoo.com/search?p=\" + s\n",
    "        response1 = get(url1)\n",
    "        url2 = \"\"\n",
    "        html_soup1 = BeautifulSoup(response1.text, 'lxml')\n",
    "        for link in html_soup1.find_all('a', href=True):\n",
    "            z = \"www.imdb.com\"\n",
    "            if z in link['href']:\n",
    "                url2 = link['href']\n",
    "                break\n",
    "        # now opening the link stored in url2\n",
    "        response2 = get(url2)\n",
    "        html_soup2 = BeautifulSoup(response2.text, 'lxml')\n",
    "        url3 = \"https://www.imdb.com\"\n",
    "        search_containers = html_soup2.find('div', class_='seasons-and-year-nav')\n",
    "        link = search_containers.find('a', href=True)  # finding the first link in search Container\n",
    "        url3 = url3 + link['href']  # url3 is the link to the page which contains information about episodes and seasons\n",
    "\n",
    "        first_series = \"\"\n",
    "        response = get(url3)\n",
    "        html_soup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "        odd_movie_containers = html_soup.find_all('div', class_='list_item odd')\n",
    "        even_movie_containers = html_soup.find_all('div', class_='list_item even')\n",
    "\n",
    "        index_odd = 0\n",
    "        index_even = 0\n",
    "        index = 0\n",
    "\n",
    "        dic = {\"Jan.\": \"01\", \"Feb.\": \"02\", \"Mar.\": \"03\", \"Apr.\": \"04\", \"May.\": \"05\", \"May\": \"05\", \"Jun.\": \"06\",\n",
    "               \"Jul.\": \"07\", \"Aug.\": \"08\", \"Sep.\": \"09\", \"Oct.\": \"10\", \"Nov.\": \"11\", \"Dec.\": \"12\"}\n",
    "        message = message + \"TV Series : \" + x + \"\\n\"  # storing TV series Name\n",
    "\n",
    "        while (index < len(odd_movie_containers) + len(even_movie_containers)):\n",
    "            date = \"\"\n",
    "            if ((index + 1) % 2 != 0 & index_odd < len(odd_movie_containers)):\n",
    "                first_series = odd_movie_containers[index_odd]\n",
    "                first_year = first_series.find('div', class_='airdate')\n",
    "                date = str(first_year.text)\n",
    "                index_odd = index_odd + 1\n",
    "            elif ((index + 1) % 2 == 0 & index_even < len(even_movie_containers)):\n",
    "                first_series = even_movie_containers[index_even]\n",
    "                first_year = first_series.find('div', class_='airdate')\n",
    "                date = str(first_year.text)\n",
    "                index_even = index_even + 1\n",
    "            date = date.strip()\n",
    "\n",
    "            if (len(date) == 0):\n",
    "                message = message + \"Status: All the seasons are finished and no further details are available\" + \"\\n\\n\"\n",
    "                break\n",
    "            else:\n",
    "                if (len(date) > 12):\n",
    "                    date = date[-12:]\n",
    "                actual_date = date\n",
    "                if (len(date) == 12):\n",
    "                    s = date[3:7]\n",
    "                    date1 = date[0] + date[1] + \"/\" + dic[s] + \"/\" + date[8:]\n",
    "                    date = date1\n",
    "                elif (len(date) == 11):\n",
    "                    s = date[3:6]\n",
    "                    if (s == \"May\"):\n",
    "                        date = date[0] + date[1] + \"/\" + dic[s] + \"/\" + date[7:]\n",
    "                    else:\n",
    "                        date = \"0\" + date\n",
    "                        s = date[3:7]\n",
    "                        date = date[0] + date[1] + \"/\" + dic[s] + \"/\" + date[8:]\n",
    "                elif (len(date) == 10):\n",
    "                    s = date[2:5]\n",
    "                    date = \"0\" + date[0] + \"/\" + dic[s] + \"/\" + date[6:]\n",
    "                elif (len(date) == 4):\n",
    "                    date = \"01/01/\" + date\n",
    "\n",
    "                new_date = time.strptime(date, \"%d/%m/%Y\")\n",
    "                present_date = str(time.strftime(\"%d/%m/%Y\"))\n",
    "                present_date = time.strptime(present_date, \"%d/%m/%Y\")\n",
    "                if (new_date >= present_date):\n",
    "                    if (len(actual_date) == 4):\n",
    "                        message = message + \"Status: The next season begins in \" + str(actual_date) + \"\\n\\n\\n\"\n",
    "                        break\n",
    "                    else:\n",
    "                        message = message + \"Status: Next episode airs on 20\" + date[8:] + \"-\" + date[3:5] + \"-\" + date[\n",
    "                                                                                                                   0:2] + \"\\n\\n\"\n",
    "                        break\n",
    "                index = index + 1\n",
    "\n",
    "        if (index == len(odd_movie_containers) + len(even_movie_containers)):\n",
    "            message = message + \"Status: All the seasons are finished and no further details are available\" + \"\\n\\n\"\n",
    "\n",
    "    return message\n",
    "\n",
    "\n",
    "@app.route(\"/\", methods=[\"GET\", \"POST\"])\n",
    "def home():\n",
    "    if request.method == \"POST\":\n",
    "        s = request.form[\"movieName\"]\n",
    "\n",
    "        if len(s) > 0:\n",
    "            result = movieDetail(s)\n",
    "            return render_template(\"result.html\", result=result)\n",
    "\n",
    "    return render_template(\"home.html\")\n",
    "\n",
    "\n",
    "@app.route(\"/episodeTracker\", methods=[\"GET\", \"POST\"])\n",
    "def tvSeries():\n",
    "    if request.method == \"POST\":\n",
    "        s = request.form[\"seriesName\"]\n",
    "\n",
    "        if len(s) > 0:\n",
    "            result = seriesDetail(s)\n",
    "            return render_template(\"seriesResult.html\", result=result)\n",
    "\n",
    "    return render_template(\"series.html\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}